{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re, time, os, json, pickle, shutil, pdfplumber\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 2018\n",
    "\n",
    "item_list = []\n",
    "\n",
    "\n",
    "\n",
    "for year in range(start, 2025):\n",
    "    print(year)\n",
    "    url = f\"https://www.ipma.pt/pt/publicacoes/boletins.jsp?cmbDep=sis&cmbTema=bsi&cmbAno={str(year)}&idDep=sis&idTema=bsi&curAno={str(year)}\"\n",
    "    #print(url)\n",
    "    response = requests.get(url)\n",
    "    stat = response.status_code\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    time.sleep(1)\n",
    "    b_url=\"https://www.ipma.pt\"\n",
    "    items = []\n",
    "\n",
    "    for i in soup.find_all(\"td\", \"class\"==\"apli_sat_img\"):\n",
    "        items.append(i.find(\"a\"))\n",
    "\n",
    "        items = list(filter(lambda items: items is not None, items))\n",
    "\n",
    "        for j in range(0,len(items)):\n",
    "            item_list.append(b_url+items[j][\"href\"])\n",
    "            \n",
    "item_list = [item for item in item_list if \"bsi_mm_pm\" in item]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_list[0].split('/')[-1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## download\n",
    "\n",
    "\n",
    "def download_file(url):\n",
    "    local_filename = url.split('/')[-1]\n",
    "    os.makedirs(local_filename.split(\".\")[0], exist_ok=True)\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "    return local_filename\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for j in item_list:\n",
    "    download_file(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = \"C:/Users/Utilizador/Desktop/IRONHACK/FinalProj/Bol/\"\n",
    "url2 = \"bc_2011-01_papel.pdf\"\n",
    "url_lib = \"C:/texlive/2021/bin/win32/pdftotext.exe\"\n",
    "\n",
    "import os, subprocess\n",
    "\n",
    "# Set the path to your PDF file\n",
    "url1 = \"C:/Users/Utilizador/Desktop/IRONHACK/FinalProj/Bol/\"\n",
    "url2 = \"bc_2011-01_papel.pdf\"\n",
    "\n",
    "# Set the path to the pdftotext executable\n",
    "pdftotext_path = f\"{url_lib}\"  # Adjust this path as necessary\n",
    "\n",
    "SCRIPT_DIR = f\"{url1}\"\n",
    "pdf_file_name = f\"{url2}\"\n",
    "pdf_file_path = os.path.join(SCRIPT_DIR, pdf_file_name)\n",
    "\n",
    "if not os.path.isfile(pdf_file_path):\n",
    "    print(f\"File {pdf_file_name} not found in {SCRIPT_DIR}.\")\n",
    "else:\n",
    "    args = [pdftotext_path,\n",
    "            '-enc', 'UTF-8',\n",
    "            pdf_file_path, '-']\n",
    "\n",
    "    res = subprocess.run(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output = res.stdout.decode('utf-8')\n",
    "\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = output.replace(\"\\n\",\"    \").split(\"    \")\n",
    "search_string = \"Listagem de Hipocentros dos Sismos Próximos\\r\"\n",
    "\n",
    "index = my_list.index(search_string)\n",
    "\n",
    "display(\" \".join(my_list[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list2 = my_list[index:]\n",
    "my_list3 = \"    \".join(my_list2)\n",
    "my_list3.split(\"    \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pdf_file_path = \"C:/Users/Utilizador/Desktop/IRONHACK/FinalProj/Bol/bc_2011-01_papel.pdf\"\n",
    "pattern = (r\"\\d\\d-\\d\\d-\\d\\d\\d\\d \\d\\d:\\d\\d:\\d\\d.\\d \\d\\d.\\d\\d\\d.\\S \\d\\d.\\d\\d\\d\")\n",
    "\n",
    "page_list=[]\n",
    "table = []\n",
    "\n",
    "with pdfplumber.open(pdf_file_path) as pdf:\n",
    "    for page in pdf.pages:\n",
    "        # Extract text\n",
    "        text = page.extract_text()\n",
    "        page_list.append(text)\n",
    "        \n",
    "        for pag in page_list:\n",
    "            paging = pag.split(\"\\n\")\n",
    "            for p in paging:\n",
    "                if re.match(pattern, p):\n",
    "                    table.append(p)\n",
    "        \"\"\"\n",
    "        # Extract tables\n",
    "        tables = page.extract_tables()\n",
    "        for table in tables:\n",
    "            for row in table:\n",
    "                \n",
    "               \n",
    "                \n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify the directory you want to scan\n",
    "directory_path = \"C:/Users/Utilizador/Desktop/IRONHACK/FinalProj/Bol/\"  # Change this to your folder path\n",
    "\n",
    "# Create a list of filenames\n",
    "file_names = [file for file in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, file))]\n",
    "\n",
    "table = []\n",
    "for file in file_names:\n",
    "    pdf_file_path = f\"C:/Users/Utilizador/Desktop/IRONHACK/FinalProj/Bol/{file}\"\n",
    "    pattern = (r\"\\d\\d-\\d\\d-\\d\\d\\d\\d \\d\\d:\\d\\d:\\d\\d.\\d \\d\\d.\\d\\d\\d.\\S \\d\\d.\\d\\d\\d\")\n",
    "\n",
    "    page_list=[]\n",
    "\n",
    "    with pdfplumber.open(pdf_file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            # Extract text\n",
    "            text = page.extract_text()\n",
    "            page_list.append(text)\n",
    "            \n",
    "    for pag in page_list:\n",
    "        paging = pag.split(\"\\n\")\n",
    "        for p in paging:\n",
    "            if re.match(pattern, p):\n",
    "                table.append(p)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[189], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtable\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'table' is not defined"
     ]
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table2 = [line.split(\",\") for line in table]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table3 = []\n",
    "\n",
    "for i in range(len(table2)):    \n",
    "    j = table2[i][0].replace(\" \",\",\")\n",
    "    table3.append(list(j))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert spaces to commas while keeping each element separate\n",
    "converted_data = [item[0].replace(\" \", \",\").split(\",\") for item in table2]\n",
    "\n",
    "# Process each row\n",
    "processed_data = []\n",
    "\n",
    "for row in converted_data:\n",
    "    if 'ml' in row:\n",
    "        ml_index = row.index('ml')  # Find the index of \"ml\"\n",
    "        \n",
    "        # Move the last element to the position after \"ml\"\n",
    "        last_element = row.pop()  # Remove the last element\n",
    "        row.insert(ml_index + 1, last_element)  # Insert it after \"ml\"\n",
    "        \n",
    "        # Join remaining elements into a single string\n",
    "        joined_row = ' '.join(row)\n",
    "        processed_data.append(joined_row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame(processed_data, columns=[\"date\",\"time\", \"lat\",\"lon\",\"depth\",,\"rms\",\"int\", \"region\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(table2, columns=[\"index\",\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"backup_in_case.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"backup_in_case_copy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Unnamed: 2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.__deepcopy__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = list(df[\"data\"])\n",
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = [s.split(\",\") for s in l1]\n",
    "\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting each string into elements\n",
    "#l3 = [s[0].split() for s in l2]\n",
    "l3 = [s[0].replace(\" ml\", \"ml\").split() for s in l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_results = []\n",
    "\n",
    "for row in l3:\n",
    "    # Look for elements that contain \"ml\"\n",
    "    ml_found = False  # Flag to track if \"ml\" is found\n",
    "    for i, element in enumerate(row):\n",
    "        if \"ml\" in element:\n",
    "            # Join all elements after the one that contains \"ml\"\n",
    "            merged_string = ' '.join(row[i + 1:])  # Join elements after \"ml\"\n",
    "            merged_results.append(merged_string)\n",
    "            ml_found = True  # Set the flag to True\n",
    "            break  # Exit the loop after finding the first \"ml\"\n",
    "    \n",
    "    if not ml_found:\n",
    "        merged_results.append(\" \")  # Append a space if \"ml\" is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern to match the numeric value at the end of the string\n",
    "pattern = r'(\\d\\.\\d)(.*)$'\n",
    "\n",
    "# Initialize lists to hold extracted values\n",
    "magnitudes = []\n",
    "parameters = []\n",
    "\n",
    "\n",
    "for entry in merged_results:\n",
    "    match = re.search(pattern, entry)\n",
    "    if match:\n",
    "        magnitudes.append(match.group(1))  # The numeric value\n",
    "        parameters.append(match.group(2).strip())  # Any parameters after the number\n",
    "    else:\n",
    "        magnitudes.append(\" \")\n",
    "        parameters.append(\" \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3_first_six_columns = [row[:6] for row in l3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3_df = pd.DataFrame(l3_first_six_columns, columns=[\"date\",\"time\", \"lat\",\"lon\",\"depth\",\"mag\"])\n",
    "display(l3_df.shape)\n",
    "l3_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_df = pd.DataFrame(magnitudes, columns=[\"Rms\"])\n",
    "display(rms_df.shape)\n",
    "rms_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_df = pd.DataFrame(parameters, columns=[\"Int\"])\n",
    "display(int_df.shape)\n",
    "int_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "together = pd.concat([l3_df, rms_df, int_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "together.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "together.to_csv(\"semi-processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "together = pd.read_csv(\"semi-processed.csv\", index_col=\"index\")\n",
    "\n",
    "# Convert 'date' to datetime\n",
    "together['date'] = pd.to_datetime(together['date'], format='%d-%m-%Y')\n",
    "\n",
    "# Convert 'time' to timedelta\n",
    "together['time'] = pd.to_timedelta(together['time'])\n",
    "\n",
    "# Combine 'date' and 'time' into a single datetime column\n",
    "together['datetime'] = together['date'] + together['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2556354</td>\n",
       "      <td>2556354</td>\n",
       "      <td>2556354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2018-05-06 21:47:02.355589376</td>\n",
       "      <td>0 days 11:36:42.679560929</td>\n",
       "      <td>2018-05-07 09:23:45.035150848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2005-01-01 00:00:00</td>\n",
       "      <td>0 days 00:00:01.500000</td>\n",
       "      <td>2005-01-01 22:42:36.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2014-12-17 00:00:00</td>\n",
       "      <td>0 days 04:44:53.100000</td>\n",
       "      <td>2014-12-17 20:04:22.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2020-02-02 00:00:00</td>\n",
       "      <td>0 days 11:19:26.400000</td>\n",
       "      <td>2020-02-02 18:30:04.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2022-02-26 00:00:00</td>\n",
       "      <td>0 days 18:31:04.500000</td>\n",
       "      <td>2022-02-26 05:41:27.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2023-10-31 00:00:00</td>\n",
       "      <td>0 days 23:59:58.200000</td>\n",
       "      <td>2023-10-31 23:29:24.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 07:23:16.196861364</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                date                       time  \\\n",
       "count                        2556354                    2556354   \n",
       "mean   2018-05-06 21:47:02.355589376  0 days 11:36:42.679560929   \n",
       "min              2005-01-01 00:00:00     0 days 00:00:01.500000   \n",
       "25%              2014-12-17 00:00:00     0 days 04:44:53.100000   \n",
       "50%              2020-02-02 00:00:00     0 days 11:19:26.400000   \n",
       "75%              2022-02-26 00:00:00     0 days 18:31:04.500000   \n",
       "max              2023-10-31 00:00:00     0 days 23:59:58.200000   \n",
       "std                              NaN  0 days 07:23:16.196861364   \n",
       "\n",
       "                            datetime  \n",
       "count                        2556354  \n",
       "mean   2018-05-07 09:23:45.035150848  \n",
       "min       2005-01-01 22:42:36.500000  \n",
       "25%       2014-12-17 20:04:22.200000  \n",
       "50%       2020-02-02 18:30:04.300000  \n",
       "75%       2022-02-26 05:41:27.400000  \n",
       "max       2023-10-31 23:29:24.500000  \n",
       "std                              NaN  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "together.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['2011-01-01 00:57:28.600000', '2011-01-01 02:43:51.300000',\n",
       " '2011-01-01 06:50:57.800000', '2011-01-01 06:58:33.700000',\n",
       " '2011-01-01 07:08:21.100000', '2011-01-01 07:09:15.100000',\n",
       " '2011-01-01 09:01:36.800000', '2011-01-01 09:03:32.900000',\n",
       "        '2011-01-01 09:13:00', '2011-01-01 09:14:02.600000',\n",
       " ...\n",
       " '2014-02-26 05:45:06.600000', '2014-02-26 09:48:58.900000',\n",
       " '2014-02-26 13:35:21.300000', '2014-02-27 02:44:31.600000',\n",
       " '2014-02-27 03:06:10.200000', '2014-02-27 04:03:29.800000',\n",
       " '2014-02-27 16:33:12.500000', '2014-02-28 00:07:00.500000',\n",
       " '2014-02-28 09:14:32.300000', '2014-02-28 10:53:15.500000']\n",
       "Length: 36134, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "together[\"datetime\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>Rms</th>\n",
       "      <th>Int</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0 days 00:57:28.600000</td>\n",
       "      <td>37.317°N</td>\n",
       "      <td>08.522°W</td>\n",
       "      <td>15</td>\n",
       "      <td>1.1ml</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-01-01 00:57:28.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0 days 02:43:51.300000</td>\n",
       "      <td>38.669°N</td>\n",
       "      <td>08.486°W</td>\n",
       "      <td>0*</td>\n",
       "      <td>0.9ml</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-01-01 02:43:51.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0 days 06:50:57.800000</td>\n",
       "      <td>36.538°N</td>\n",
       "      <td>07.663°W</td>\n",
       "      <td>31*</td>\n",
       "      <td>1.5ml</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-01-01 06:50:57.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0 days 06:58:33.700000</td>\n",
       "      <td>36.355°N</td>\n",
       "      <td>09.698°W</td>\n",
       "      <td>31*</td>\n",
       "      <td>1.7ml</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-01-01 06:58:33.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0 days 07:08:21.100000</td>\n",
       "      <td>37.036°N</td>\n",
       "      <td>04.850°W</td>\n",
       "      <td>0*</td>\n",
       "      <td>1.9ml</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-01-01 07:08:21.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556349</th>\n",
       "      <td>2014-02-27</td>\n",
       "      <td>0 days 04:03:29.800000</td>\n",
       "      <td>37.333°N</td>\n",
       "      <td>08.511°W</td>\n",
       "      <td>12</td>\n",
       "      <td>0.9ml</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-02-27 04:03:29.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556350</th>\n",
       "      <td>2014-02-27</td>\n",
       "      <td>0 days 16:33:12.500000</td>\n",
       "      <td>33.146°N</td>\n",
       "      <td>05.111°W</td>\n",
       "      <td>10*</td>\n",
       "      <td>2.2ml</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-02-27 16:33:12.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556351</th>\n",
       "      <td>2014-02-28</td>\n",
       "      <td>0 days 00:07:00.500000</td>\n",
       "      <td>42.426°N</td>\n",
       "      <td>08.100°W</td>\n",
       "      <td>0*</td>\n",
       "      <td>1.5ml</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-02-28 00:07:00.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556352</th>\n",
       "      <td>2014-02-28</td>\n",
       "      <td>0 days 09:14:32.300000</td>\n",
       "      <td>38.996°N</td>\n",
       "      <td>09.021°W</td>\n",
       "      <td>3</td>\n",
       "      <td>1.9ml</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-02-28 09:14:32.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556353</th>\n",
       "      <td>2014-02-28</td>\n",
       "      <td>0 days 10:53:15.500000</td>\n",
       "      <td>36.443°N</td>\n",
       "      <td>09.914°W</td>\n",
       "      <td>32</td>\n",
       "      <td>1.7ml</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-02-28 10:53:15.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2556354 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date                   time       lat       lon depth    mag  \\\n",
       "index                                                                        \n",
       "0       2011-01-01 0 days 00:57:28.600000  37.317°N  08.522°W    15  1.1ml   \n",
       "1       2011-01-01 0 days 02:43:51.300000  38.669°N  08.486°W    0*  0.9ml   \n",
       "2       2011-01-01 0 days 06:50:57.800000  36.538°N  07.663°W   31*  1.5ml   \n",
       "3       2011-01-01 0 days 06:58:33.700000  36.355°N  09.698°W   31*  1.7ml   \n",
       "4       2011-01-01 0 days 07:08:21.100000  37.036°N  04.850°W    0*  1.9ml   \n",
       "...            ...                    ...       ...       ...   ...    ...   \n",
       "2556349 2014-02-27 0 days 04:03:29.800000  37.333°N  08.511°W    12  0.9ml   \n",
       "2556350 2014-02-27 0 days 16:33:12.500000  33.146°N  05.111°W   10*  2.2ml   \n",
       "2556351 2014-02-28 0 days 00:07:00.500000  42.426°N  08.100°W    0*  1.5ml   \n",
       "2556352 2014-02-28 0 days 09:14:32.300000  38.996°N  09.021°W     3  1.9ml   \n",
       "2556353 2014-02-28 0 days 10:53:15.500000  36.443°N  09.914°W    32  1.7ml   \n",
       "\n",
       "         Rms  Int                datetime  \n",
       "index                                      \n",
       "0        0.4  NaN 2011-01-01 00:57:28.600  \n",
       "1        0.3  NaN 2011-01-01 02:43:51.300  \n",
       "2        0.3  NaN 2011-01-01 06:50:57.800  \n",
       "3        0.3  NaN 2011-01-01 06:58:33.700  \n",
       "4        0.4  NaN 2011-01-01 07:08:21.100  \n",
       "...      ...  ...                     ...  \n",
       "2556349  0.3  NaN 2014-02-27 04:03:29.800  \n",
       "2556350  0.4  NaN 2014-02-27 16:33:12.500  \n",
       "2556351  0.3  NaN 2014-02-28 00:07:00.500  \n",
       "2556352  0.4  NaN 2014-02-28 09:14:32.300  \n",
       "2556353  0.4  NaN 2014-02-28 10:53:15.500  \n",
       "\n",
       "[2556354 rows x 9 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "together"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda3-12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
