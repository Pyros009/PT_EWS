{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re, time, os, json, pickle, shutil, pdfplumber, zipfile, math\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 2005\n",
    "\n",
    "item_list = []\n",
    "\n",
    "for year in range(start, 2025):\n",
    "    print(year)\n",
    "    url = f\"https://www.ipma.pt/pt/publicacoes/boletins.jsp?cmbDep=sis&cmbTema=bsi&cmbAno={str(year)}&idDep=sis&idTema=bsi&curAno={str(year)}\"\n",
    "    response = requests.get(url)\n",
    "    stat = response.status_code\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    time.sleep(1)\n",
    "    b_url=\"https://www.ipma.pt\"\n",
    "    items = []\n",
    "\n",
    "    for i in soup.find_all(\"td\", \"class\"==\"apli_sat_img\"):\n",
    "        items.append(i.find(\"a\"))\n",
    "\n",
    "        items = list(filter(lambda items: items is not None, items))\n",
    "\n",
    "        for j in range(0,len(items)):\n",
    "            item_list.append(b_url+items[j][\"href\"])\n",
    "            \n",
    "item_list = [item for item in item_list if \"bsi_mm_pm\" in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_list[0].split('/')[-1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## download to /data\n",
    "\n",
    "def download_file(url):\n",
    "    local_filename = url.split('/')[-1]\n",
    "    current_dir = os.getcwd()\n",
    "    root_dir = os.path.abspath(os.path.join(current_dir, '..', '..')) \n",
    "    save_path = os.path.join(root_dir, 'data', local_filename)\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        with open(save_path, 'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "    return local_filename\n",
    "\n",
    "for j in item_list:\n",
    "    download_file(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the zip file folder\n",
    "current_dir = os.getcwd()\n",
    "root_dir = os.path.abspath(os.path.join(current_dir, '..', '..'))\n",
    "directory_path = os.path.join(root_dir, 'data') # Change this to your folder path\n",
    "\n",
    "# Create a list of filenames\n",
    "zip_files = [os.path.join(directory_path, file) for file in os.listdir(directory_path) if file.lower().endswith('.zip')]\n",
    "\n",
    "def unzip_pdfs(zip_files, extract_to_folder):\n",
    "    os.makedirs(extract_to_folder, exist_ok=True)\n",
    "    for zip_file in zip_files:\n",
    "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "            for file_name in zip_ref.namelist():\n",
    "                if file_name.lower().endswith('.pdf'):\n",
    "                    zip_ref.extract(file_name, extract_to_folder)\n",
    "\n",
    "extract_to_folder = os.path.join(directory_path, 'pdfs')  # Folder to save the extracted PDFs\n",
    "unzip_pdfs(zip_files, extract_to_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the pdfs folder\n",
    "current_dir = os.getcwd()\n",
    "root_dir = os.path.abspath(os.path.join(current_dir, '..', '..'))\n",
    "directory_path = os.path.join(root_dir, 'data', 'pdfs')\n",
    "\n",
    "file_names = [file for file in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, file))]\n",
    "\n",
    "table = []\n",
    "for file in file_names:\n",
    "    pdf_file_path = os.path.join(root_dir, 'data','pdfs', file)\n",
    "    print(pdf_file_path)\n",
    "    pattern = (r\"\\d\\d-\\d\\d-\\d\\d\\d\\d \\d\\d:\\d\\d:\\d\\d.\\d \\d\\d.\\d\\d\\d.\\S \\d\\d.\\d\\d\\d\")\n",
    "\n",
    "    page_list=[]\n",
    "\n",
    "    with pdfplumber.open(pdf_file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            # Extract text\n",
    "            text = page.extract_text()\n",
    "            page_list.append(text)\n",
    "            \n",
    "    for pag in page_list:\n",
    "        paging = pag.split(\"\\n\")\n",
    "        for p in paging:\n",
    "            if re.match(pattern, p):\n",
    "                table.append(p)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table2 = [line.split(\",\") for line in table]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table3 = []\n",
    "\n",
    "for i in range(len(table2)):    \n",
    "    j = table2[i][0].replace(\" \",\",\")\n",
    "    table3.append(list(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert spaces to commas while keeping each element separate\n",
    "converted_data = [item[0].replace(\" \", \",\").split(\",\") for item in table2]\n",
    "\n",
    "# Process each row\n",
    "processed_data = []\n",
    "\n",
    "for row in converted_data:\n",
    "    if 'ml' in row:\n",
    "        ml_index = row.index('ml')  # Find the index of \"ml\"\n",
    "        \n",
    "        # Move the last element to the position after \"ml\"\n",
    "        last_element = row.pop()  # Remove the last element\n",
    "        row.insert(ml_index + 1, last_element)  # Insert it after \"ml\"\n",
    "        \n",
    "        # Join remaining elements into a single string\n",
    "        joined_row = ' '.join(row)\n",
    "        processed_data.append(joined_row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(table2, columns=[\"data\"])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = list(df[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = [s.split(\",\") for s in l1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting each string into elements\n",
    "l3 = [s[0].replace(\" ml\", \"ml\").split() for s in l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_results = []\n",
    "\n",
    "for row in l3:\n",
    "    # Look for elements that contain \"ml\"\n",
    "    ml_found = False  # Flag to track if \"ml\" is found\n",
    "    for i, element in enumerate(row):\n",
    "        if \"ml\" in element:\n",
    "            # Join all elements after the one that contains \"ml\"\n",
    "            merged_string = ' '.join(row[i + 1:])  # Join elements after \"ml\"\n",
    "            merged_results.append(merged_string)\n",
    "            ml_found = True  # Set the flag to True\n",
    "            break  # Exit the loop after finding the first \"ml\"\n",
    "    \n",
    "    if not ml_found:\n",
    "        merged_results.append(\" \")  # Append a space if \"ml\" is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern to match the numeric value at the end of the string\n",
    "pattern = r'(\\d\\.\\d)(.*)$'\n",
    "\n",
    "# Initialize lists to hold extracted values\n",
    "magnitudes = []\n",
    "parameters = []\n",
    "\n",
    "\n",
    "for entry in merged_results:\n",
    "    match = re.search(pattern, entry)\n",
    "    if match:\n",
    "        magnitudes.append(match.group(1))  # The numeric value\n",
    "        parameters.append(match.group(2).strip())  # Any parameters after the number\n",
    "    else:\n",
    "        magnitudes.append(\" \")\n",
    "        parameters.append(\" \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3_first_six_columns = [row[:6] for row in l3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3_df = pd.DataFrame(l3_first_six_columns, columns=[\"date\",\"time\", \"lat\",\"lon\",\"depth\",\"mag\"])\n",
    "display(l3_df.shape)\n",
    "l3_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_df = pd.DataFrame(magnitudes, columns=[\"Rms\"])\n",
    "display(rms_df.shape)\n",
    "rms_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_df = pd.DataFrame(parameters, columns=[\"Int\"])\n",
    "display(int_df.shape)\n",
    "int_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "together = pd.concat([l3_df, rms_df, int_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "together.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' to datetime\n",
    "together['date'] = pd.to_datetime(together['date'], format='%d-%m-%Y')\n",
    "\n",
    "# Convert 'time' to timedelta\n",
    "together['time'] = pd.to_timedelta(together['time'])\n",
    "\n",
    "# Combine 'date' and 'time' into a single datetime column\n",
    "together['datetime'] = together['date'] + together['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "together.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "together.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "together.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "together = together.drop(columns=[\"date\", \"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "together2 = together.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'ml' from the 'mag' column\n",
    "together2['mag'] = together2['mag'].str.replace('ml', '', regex=False)\n",
    "together2['depth'] = together2['depth'].str.replace('*', '', regex=False)\n",
    "\n",
    "# Optionally, convert the 'mag' column to numeric if needed\n",
    "together2['mag'] = pd.to_numeric(together2['mag'], errors='coerce')\n",
    "# Optionally, convert the 'mag' column to numeric if needed\n",
    "together2['Rms'] = pd.to_numeric(together2['Rms'], errors='coerce')\n",
    "# Optionally, convert the 'mag' column to numeric if needed\n",
    "together2['depth'] = pd.to_numeric(together2['depth'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "together3 = together2.set_index(\"datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "together3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#together3[\"sensed\"] = together3.apply(lambda x: 1 if together3[\"Int\"].isnull else 0)\n",
    "together3['sensed'] = (together3['Int'].notnull() & (together3['Int'] != \"\") & (together3['Int'] != \" \"))\n",
    "together3['sensed'] = together3['sensed'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert latitude and longitude to decimal\n",
    "def convert_lat_lon(lat, lon):\n",
    "    # Convert latitude\n",
    "    lat_value = float(lat[:-2])  # Get the numeric part\n",
    "    if lat.endswith('S'):  # South is negative\n",
    "        lat_value = -lat_value\n",
    "    \n",
    "    # Convert longitude\n",
    "    lon_value = float(lon[:-2])  # Get the numeric part\n",
    "    if lon.endswith('W'):  # West is negative\n",
    "        lon_value = -lon_value\n",
    "    \n",
    "    return lat_value, lon_value\n",
    "\n",
    "# Apply the conversion function\n",
    "together3[['lat_decimal', 'lon_decimal']] = together3.apply(\n",
    "    lambda row: pd.Series(convert_lat_lon(row['lat'], row['lon'])),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lat_lon(coord):\n",
    "    c_value = float(coord[:-2])  # Remove the last two characters (°N or °S)\n",
    "    \n",
    "\n",
    "    if ('S' in coord or \"W\" in coord):\n",
    "        c_value = -c_value  # Convert to negative for South\n",
    "    \n",
    "    \n",
    "    return c_value\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "    \n",
    "    # Radius of Earth in kilometers (mean radius)\n",
    "    r = 6371.0\n",
    "    distance = r * c\n",
    "    return distance\n",
    "\n",
    "# MORF\n",
    "latitude = 37.304321\n",
    "longitude  = -8.652672\n",
    "\n",
    "# Example usage\n",
    "event_lat = 34.05  # Latitude of event\n",
    "event_lon = -118.25  # Longitude of event\n",
    "station_lat = latitude  # Latitude of station\n",
    "station_lon = longitude  # Longitude of station\n",
    "\n",
    "together3[\"dist_MORF\"] = together3.apply(lambda row: haversine(convert_lat_lon(row[\"lat\"]), convert_lat_lon(row[\"lon\"]), station_lat, station_lon), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the save folder\n",
    "current_dir = os.getcwd()\n",
    "root_dir = os.path.abspath(os.path.join(current_dir, '..', '..'))\n",
    "directory_path = os.path.join(root_dir, 'dbs') # Change this to your folder path\n",
    "os.makedirs(directory_path, exist_ok=True)\n",
    "file_path = os.path.join(directory_path, \"checkpoint1.csv\")\n",
    "together3.to_csv(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
