{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import Trace, UTCDateTime, Stream # type: ignore\n",
    "from obspy.clients.fdsn import Client as FDSNclient # type: ignore\n",
    "from obspy.core.inventory import Inventory # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "from bs4 import BeautifulSoup # type: ignore\n",
    "import requests # type: ignore\n",
    "import logging.handlers\n",
    "import numpy as np # type: ignore\n",
    "import logging\n",
    "from multiprocessing import Queue\n",
    "import pandas as pd # type: ignore\n",
    "from src.filtering import filtering_data\n",
    "from src.fourier import fourier_transform\n",
    "from src.core import main_processing\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source data\n",
    "datasource = pd.read_csv(\"checkpoint1.csv\", index_col=\"index\")\n",
    "datasource[\"datetime\"] = datasource[\"datetime\"].str.replace(\" \",\"T\")\n",
    "datasource.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource[\n",
    "    (datasource[\"datetime\"] > \"2009-09-21\")\n",
    "    &(datasource[\"sensed\"] == 1)\n",
    "    #&(datasource[\"Int\"] == \"II\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_filtered = datasource[\n",
    "    (datasource[\"datetime\"] > \"2009-09-21\")\n",
    "    #&(datasource[\"sensed\"] == 1)\n",
    "    #&(datasource[\"dist_MORF\"] < 300)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = ds_filtered.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_table = []\n",
    "\n",
    "# Define your processing function\n",
    "def process_index(eq):\n",
    "    try:\n",
    "        d_t = datasource.iloc[eq]  # Get the row based on index eq\n",
    "        \n",
    "        url = 'rtserve.iris.washington.edu:18000'\n",
    "        source = {\n",
    "            \"LX\": {\"MORF\": [\"BHE\", \"BHN\", \"BHZ\"]}\n",
    "        }\n",
    "\n",
    "        loc = '--'\n",
    "        earliest_date = \"2009-09-21T15:18:14.919538Z\"\n",
    "        ref_time = UTCDateTime(str(d_t[\"datetime\"]))\n",
    "        client = FDSNclient(\"IRIS\")\n",
    "        gap = 120\n",
    "\n",
    "        starttime = ref_time - gap  # 2 minutes before\n",
    "        endtime = ref_time + gap  # 2 minutes after\n",
    "\n",
    "        st = None\n",
    "        \n",
    "        # Attempt to print available streams\n",
    "        for server, values in source.items():\n",
    "            for channel, ch in values.items():\n",
    "                for i in ch:\n",
    "                    trace = client.get_waveforms(server, channel, loc, i, starttime, endtime, attach_response=True)\n",
    "                    \n",
    "                    if st is None:\n",
    "                        st = trace\n",
    "                    else:\n",
    "                        st += trace  # Use += to concatenate traces\n",
    "\n",
    "        st2 = st.copy()\n",
    "\n",
    "        # Process components\n",
    "        st_z = st.select(component=\"Z\")\n",
    "        st_n = st.select(component=\"N\")\n",
    "        st_e = st.select(component=\"E\")\n",
    "\n",
    "        filtered_z, time_vector_z = filtering_data(st2.select(component=\"Z\")[0])\n",
    "        filtered_n, time_vector_n = filtering_data(st2.select(component=\"N\")[0])\n",
    "        filtered_e, time_vector_e = filtering_data(st2.select(component=\"E\")[0])\n",
    "\n",
    "        # Process Z component\n",
    "        if len(st_z) > 0:\n",
    "            dom_freq_z, amp_z = fourier_transform(filtered_z, st_z[0])\n",
    "            datasource.loc[eq, \"Domin_freq_z\"] = dom_freq_z\n",
    "        else:\n",
    "            print(\"No Z component traces available.\")\n",
    "\n",
    "        # Process N component\n",
    "        if len(st_n) > 0:\n",
    "            dom_freq_n, amp_n = fourier_transform(filtered_n, st_n[0])\n",
    "            datasource.loc[eq, \"Domin_freq_n\"] = dom_freq_n\n",
    "        else:\n",
    "            print(\"No N component traces available.\")\n",
    "\n",
    "        # Process E component\n",
    "        if len(st_e) > 0:\n",
    "            dom_freq_e, amp_e = fourier_transform(filtered_e, st_e[0])\n",
    "            datasource.loc[eq, \"Domin_freq_e\"] = dom_freq_e\n",
    "        else:\n",
    "            print(\"No E component traces available.\")\n",
    "\n",
    "        details = main_processing(filtered_z, gap, dom_freq_z)\n",
    "        #display(details)\n",
    "\n",
    "        for key, dicts in details.items():\n",
    "            if key == 1:\n",
    "                for stat, values in dicts.items():\n",
    "                    if stat == \"Vel Amp (m/s)\":\n",
    "                        datasource.loc[eq, \"P-Vel amp (m/s)\"] = values\n",
    "                    elif stat == \"Disp Amp (m)\":\n",
    "                        datasource.loc[eq, \"P-Disp amp (m)\"] = values\n",
    "                    elif stat == \"peak2peak\":\n",
    "                        datasource.loc[eq, \"P-peak2peak\"] = values\n",
    "                    elif stat == \"r\":\n",
    "                        datasource.loc[eq, \"P-r\"] = values\n",
    "                    elif stat == \"moment_history\":\n",
    "                        datasource.loc[eq, \"P-moment_history\"] = values\n",
    "                    elif stat == \"tau_c\":\n",
    "                        datasource.loc[eq, \"P-tau_c\"] = values    \n",
    "                    else:\n",
    "                        print(f\"{key} error\")\n",
    "            elif key == 2:\n",
    "                for stat, values in dicts.items():\n",
    "                    if stat == \"Vel Amp (m/s)\":\n",
    "                        datasource.loc[eq, \"S-Vel amp (m/s)\"] = values\n",
    "                    elif stat == \"Disp Amp (m)\":\n",
    "                        datasource.loc[eq, \"S-Disp amp (m)\"] = values\n",
    "                    elif stat == \"peak2peak\":\n",
    "                        datasource.loc[eq, \"S-peak2peak\"] = values\n",
    "                    elif stat == \"r\":\n",
    "                        datasource.loc[eq, \"S-r\"] = values\n",
    "                    elif stat == \"moment_history\":\n",
    "                        datasource.loc[eq, \"S-moment_history\"] = values\n",
    "                    elif stat == \"tau_c\":\n",
    "                        datasource.loc[eq, \"S-tau_c\"] = values    \n",
    "                    else:\n",
    "                        print(f\"{key} error\")\n",
    "            elif key == \"RMS\":\n",
    "                datasource.loc[eq, \"RMS\"] = dicts    \n",
    "            elif key == \"Energy\":\n",
    "                datasource.loc[eq, \"Energy\"] = dicts \n",
    "            elif key == \"peak_freq\":\n",
    "                datasource.loc[eq, \"peak_freq\"] = dicts \n",
    "            elif key == \"wavelength\":\n",
    "                datasource.loc[eq, \"wavelength\"] = dicts \n",
    "            elif key == \"peak_disp\":\n",
    "                datasource.loc[eq, \"peak_disp\"] = dicts \n",
    "            elif key == \"M0\":\n",
    "                datasource.loc[eq, \"M0\"] = dicts \n",
    "            else:\n",
    "                datasource.loc[eq, \"other infos\"] = values\n",
    "\n",
    "        print(f\"...Finished processing {eq}\")    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching index: {eq}, Error: {e}\")\n",
    "        error_table.append(eq)\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "if __name__ == \"__main__\":\n",
    "    with ThreadPoolExecutor(max_workers=12) as executor:\n",
    "        executor.map(process_index, l1)\n",
    "\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasource.to_csv(\"processed_ds2_partial.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
